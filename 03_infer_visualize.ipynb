{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 03_infer_visualize\n",
        "\n",
        "Inference and visualization on unseen Region B.\n",
        "\n",
        "- Loads best checkpoint saved by `02_train.ipynb`\n",
        "- Loads preprocessed tiles from Region B\n",
        "- Runs tile-by-tile inference; stitching can be added if tiling indices are available\n",
        "- Binarizes predictions at threshold (default 0.5)\n",
        "- Computes Dice, IoU, MCC using ground-truth masks\n",
        "- Visualizes RGB with predicted mask overlay and saves to `results/`\n",
        "\n",
        "```python\n",
        "# Colab setup (uncomment if running on Colab)\n",
        "# !pip -q install torch torchvision numpy pandas scikit-learn opencv-python pillow tqdm matplotlib rasterio\n",
        "# from pathlib import Path\n",
        "# for p in [\"data/images\",\"data/masks\",\"data/preprocessed\",\"checkpoints\",\"results\"]:\n",
        "#     Path(p).mkdir(parents=True, exist_ok=True)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "# Reuse metrics from 02_train; redefining here for standalone\n",
        "\n",
        "def dice_coefficient(prob: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
        "    if prob.shape[1] == 2:\n",
        "        prob_bin = torch.softmax(prob, dim=1)[:, 1]\n",
        "    else:\n",
        "        prob_bin = torch.sigmoid(prob[:, 0])\n",
        "    target = target.float()\n",
        "    intersection = (prob_bin * target).sum(dim=(1,2))\n",
        "    union = prob_bin.sum(dim=(1,2)) + target.sum(dim=(1,2))\n",
        "    dice = (2 * intersection + eps) / (union + eps)\n",
        "    return dice.mean()\n",
        "\n",
        "\n",
        "def iou_score(prob: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
        "    if prob.shape[1] == 2:\n",
        "        prob_bin = (torch.softmax(prob, dim=1)[:, 1] > 0.5).float()\n",
        "    else:\n",
        "        prob_bin = (torch.sigmoid(prob[:, 0]) > 0.5).float()\n",
        "    target = target.float()\n",
        "    intersection = (prob_bin * target).sum(dim=(1,2))\n",
        "    union = (prob_bin + target).clamp(0,1).sum(dim=(1,2))\n",
        "    return ((intersection + eps) / (union + eps)).mean()\n",
        "\n",
        "\n",
        "def matthews_corrcoef(prob: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
        "    if prob.shape[1] == 2:\n",
        "        pred = (torch.softmax(prob, dim=1)[:, 1] > 0.5).float()\n",
        "    else:\n",
        "        pred = (torch.sigmoid(prob[:, 0]) > 0.5).float()\n",
        "    target = target.float()\n",
        "    tp = (pred * target).sum(dim=(1,2))\n",
        "    tn = ((1 - pred) * (1 - target)).sum(dim=(1,2))\n",
        "    fp = (pred * (1 - target)).sum(dim=(1,2))\n",
        "    fn = ((1 - pred) * target).sum(dim=(1,2))\n",
        "    numerator = (tp * tn - fp * fn)\n",
        "    denominator = torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) + eps)\n",
        "    return (numerator / (denominator + eps)).mean()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class InferConfig:\n",
        "    data_dir: Path = Path(\"data/preprocessed\")\n",
        "    region_filter: str = \"RegionB\"  # unseen region\n",
        "    file_ext: str = \".npz\"  # or \".pt\"\n",
        "    input_channels: int = 6  # must match training\n",
        "    num_classes: int = 2\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    checkpoint_path: Path = Path(\"checkpoints/best_mcc.pt\")\n",
        "    results_dir: Path = Path(\"results\")\n",
        "    threshold: float = 0.5\n",
        "\n",
        "\n",
        "cfg = InferConfig()\n",
        "cfg.results_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RegionDataset(Dataset):\n",
        "    def __init__(self, directory: Path, file_ext: str, region_filter: str):\n",
        "        self.paths = sorted([p for p in directory.glob(f\"*{file_ext}\") if region_filter in p.name])\n",
        "        if len(self.paths) == 0:\n",
        "            raise FileNotFoundError(f\"No files for region {region_filter} in {directory}\")\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def __getitem__(self, idx: int):\n",
        "        path = self.paths[idx]\n",
        "        if path.suffix == \".npz\":\n",
        "            data = np.load(path)\n",
        "            image = data[\"image\"].astype(np.float32)\n",
        "            mask = data[\"mask\"].astype(np.uint8)\n",
        "        else:\n",
        "            data = torch.load(path)\n",
        "            image = data[\"image\"].numpy().astype(np.float32)\n",
        "            mask = data[\"mask\"].numpy().astype(np.uint8)\n",
        "        x = torch.from_numpy(image)\n",
        "        y = torch.from_numpy(mask).long()\n",
        "        return x, y, path.name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define UNet to match training\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
        "        self.dropout = nn.Dropout2d(p=dropout)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.dropout(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        return x\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
        "        self.conv = ConvBlock(in_ch, out_ch, dropout)\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([skip, x], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels: int, num_classes: int = 2, base_ch: int = 32, depth: int = 4, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        ch_in = in_channels\n",
        "        ch_out = base_ch\n",
        "        for _ in range(depth):\n",
        "            self.downs.append(ConvBlock(ch_in, ch_out, dropout))\n",
        "            ch_in, ch_out = ch_out, ch_out * 2\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.mid = ConvBlock(ch_in, ch_out, dropout)\n",
        "        ch_in, ch_out = ch_out, ch_out // 2\n",
        "        for _ in range(depth):\n",
        "            self.ups.append(UpBlock(ch_in, ch_out, dropout))\n",
        "            ch_in, ch_out = ch_out, ch_out // 2\n",
        "        self.seg = nn.Conv2d(ch_in * 2, num_classes, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for block in self.downs:\n",
        "            x = block(x)\n",
        "            skips.append(x)\n",
        "            x = self.pool(x)\n",
        "        x = self.mid(x)\n",
        "        for block in self.ups:\n",
        "            x = block(x, skips.pop())\n",
        "        x = self.seg(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load checkpoint and dataset\n",
        "cfg = cfg  # keep reference\n",
        "\n",
        "region_ds = RegionDataset(cfg.data_dir, cfg.file_ext, cfg.region_filter)\n",
        "if len(region_ds) == 0:\n",
        "    print(f\"Warning: No files found in {cfg.data_dir} with extension {cfg.file_ext} and filter {cfg.region_filter}\")\n",
        "else:\n",
        "    sample_x, _, _ = region_ds[0]\n",
        "    assert sample_x.shape[0] == cfg.input_channels, \\\n",
        "        f\"Mismatch: data has {sample_x.shape[0]} channels but cfg.input_channels={cfg.input_channels}. Update config.\"\n",
        "\n",
        "model = UNet(in_channels=cfg.input_channels, num_classes=2)\n",
        "state = torch.load(cfg.checkpoint_path, map_location=cfg.device)\n",
        "model.load_state_dict(state[\"model_state\"]) if isinstance(state, dict) and \"model_state\" in state else model.load_state_dict(state)\n",
        "model = model.to(cfg.device).eval()\n",
        "\n",
        "loader = DataLoader(region_ds, batch_size=1, shuffle=False)\n",
        "print(f\"Loaded {len(region_ds)} tiles for {cfg.region_filter}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tile-wise inference and optional stitching\n",
        "\n",
        "def infer_tile(x: torch.Tensor, model: nn.Module, device: str) -> torch.Tensor:\n",
        "    with torch.no_grad():\n",
        "        logits = model(x.to(device))\n",
        "    return logits.cpu()\n",
        "\n",
        "all_metrics = {\"dice\": [], \"iou\": [], \"mcc\": []}\n",
        "threshold = cfg.threshold\n",
        "\n",
        "for x, y, name in loader:\n",
        "    logits = infer_tile(x, model, cfg.device)\n",
        "    # compute metrics per tile\n",
        "    dice = dice_coefficient(logits, y)\n",
        "    iou = iou_score(logits, y)\n",
        "    mcc = matthews_corrcoef(logits, y)\n",
        "    all_metrics[\"dice\"].append(float(dice))\n",
        "    all_metrics[\"iou\"].append(float(iou))\n",
        "    all_metrics[\"mcc\"].append(float(mcc))\n",
        "\n",
        "print({k: float(np.mean(v)) for k, v in all_metrics.items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: RGB overlay with predicted mask\n",
        "\n",
        "def overlay_rgb_mask(x: torch.Tensor, logits: torch.Tensor, threshold: float = 0.5) -> np.ndarray:\n",
        "    # x: (1,C,H,W), logits: (1,2,H,W) or (1,1,H,W)\n",
        "    x_np = x.squeeze(0).cpu().numpy()\n",
        "    # channels: [B,G,R,SWIR,THERM(,NDSI)]\n",
        "    blue = x_np[0]; green = x_np[1]; red = x_np[2]\n",
        "    # denormalized visualization: scale to 0..1 per band for display\n",
        "    def scale01(a):\n",
        "        a = a - a.min()\n",
        "        d = a.max() - a.min() + 1e-6\n",
        "        return (a / d).clip(0,1)\n",
        "    rgb = np.stack([scale01(red), scale01(green), scale01(blue)], axis=-1)  # H,W,3 in 0..1\n",
        "    if logits.shape[1] == 2:\n",
        "        prob = torch.softmax(logits, dim=1)[:, 1].squeeze(0).cpu().numpy()\n",
        "    else:\n",
        "        prob = torch.sigmoid(logits[:, 0]).squeeze(0).cpu().numpy()\n",
        "    mask = (prob > threshold).astype(np.float32)\n",
        "    overlay = rgb.copy()\n",
        "    overlay[..., 0] = np.maximum(overlay[..., 0], mask)  # enhance red channel\n",
        "    return (overlay * 255).astype(np.uint8)\n",
        "\n",
        "for x, y, name in loader:\n",
        "    logits = infer_tile(x, model, cfg.device)\n",
        "    img = overlay_rgb_mask(x, logits, threshold)\n",
        "    out_path = cfg.results_dir / f\"overlay_{name}.png\"\n",
        "    plt.imsave(out_path.as_posix(), img)\n",
        "\n",
        "print(f\"Saved overlays to {cfg.results_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
